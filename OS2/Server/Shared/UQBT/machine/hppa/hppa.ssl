#
# Copyright (C) 2001, The University of Queensland
# Copyright (C) 2001, Sun Microsystems, Inc
#
# See the file "LICENSE.TERMS" for information on usage and
# redistribution of this file, and for a DISCLAIMER OF ALL
# WARRANTIES.
#

###############################################################################
# FILE:     hppa.ssl
# OVERVIEW: This file contains a semantic description of the pa/risc processor.
#
# Copyright (C) 2001, The University of Queensland, BT group
# Copyright (C) 2001, Sun Microsystems, Inc
################################################################################

# $Revision: 1.26 $

#    Apr 01 - Simon: Created
# 01 May 01 - Mike: Worked around a problem with BORR_VAL; ARITH_CB needed {};
#               added dummy SUBFLAGS; added integer registers
# 08 May 01 - Mike: "CC0" -> "" for now (fixes OR instruction); various changes
#               mainly to arguments to get hello world working
# 09 May 01 - Cristina: added some branching instrs to SSL spec
# 13 May 01 - Mike: Added another temp hack for ADD.l
# 28 Jun 01 - Mike: Mods for V1.1 opcodes
# 17 Jul 01 - Simon: Updated arith instructions
# 25 Jul 01 - Mike: Rounded out loads and stores, including floats; FP regs;
#               started floating point operations
# 25 Jul 01 - Simon: Added some shift, extract, and deposit
# 26 Jul 01 - Mike: Inserted assignments to r[tmpNul] where needed
# 26 Jul 01 - Simon: Added EXTRU
# 27 Jul 01 - Simon: More extract and deposit, %cr registers, shladds
# 27 Jul 01 - Mike: Added XMPYU
# 27 Jul 01 - Mike: Added quad registers and FLOAT keyword
# 29 Jul 01 - Simon: Minor fixes to extract instructions
# 06 Aug 01 - Mike: Added semantics for the add part of ADD[I]B; added %sar
#              and semantics for ZVDEP; MTCTL (really MTSAR)
# 07 Aug 01 - Mike: Oops, had semantics for ZDEP and ZVDEP backwards
# 07 Aug 01 - Simon: Changed iloads and istores to take more parameters, so
#               that the addressing mode details are explicit in the SSL now
# 10 Aug 01 - Simon: Fixed %sar -> -1 to -> 267. Added rest of *DEP*
#               instructions. Added c_bit lambdas.
# 14 Aug 01 - Simon: Fix DEP series for case with (len-1) > %sar
# 21 Aug 01 - Mike: Some conditional assignments for float sizes
# 28 Aug 01 - Mike: FCNVFF needed parentheses to get precedence right in guard

INTEGER
  [ %r0,  %r1,  %r2,  %r3,  %r4,  %r5,  %r6,  %r7,
    %r8,  %r9,  %r10, %r11, %r12, %r13, %r14, %r15,
    %r16, %r17, %r18, %r19, %r20, %r21, %r22, %r23,
    %r24, %r25, %r26, %r27, %r28, %r29, %r30, %r31 ][32] -> 0..31,

  [ %cr0,  %cr1,  %cr2,  %cr3,  %cr4,  %cr5,  %cr6,  %cr7,
    %cr8,  %cr9,  %cr10, %cr11, %cr12, %cr13, %cr14, %cr15, 
    %cr16, %cr17, %cr18, %cr19, %cr20, %cr21, %cr22, %cr23, 
    %cr24, %cr25, %cr26, %cr27, %cr28, %cr29, %cr30, %cr31 ][32] -> 256..287,

    %sp[32] -> 30,          # Aliases
    %rp[32] -> 2,           # Return value register
    %dp[32] -> 27,          # Global data pointer
      
    [ %ZF, %CF, %OF, %NF ][1] -> -1,    # We really don't want %ZF etc, only %CF
    %pc[32]  -> -1,
    %npc[32] -> -1,
    %sar[32] -> 267;         # Shift amount register (%cr11)
FLOAT

# Floating point quad registers
    %fq0 [128] -> 128,
    %fq2 [128] -> 130,
    %fq4 [128] -> 132,
    %fq6 [128] -> 134,
    %fq8 [128] -> 136,
    %fq10[128] -> 138,
    %fq12[128] -> 140,
    %fq14[128] -> 142,
    %fq16[128] -> 144,
    %fq18[128] -> 146,
    %fq20[128] -> 148,
    %fq22[128] -> 150,
    %fq24[128] -> 152,
    %fq26[128] -> 154,
    %fq28[128] -> 156,
    %fq30[128] -> 158,
# Floating point double registers
    %fd0  [64] -> 32  SHARES %fq0@[64..127],
    %fd1  [64] -> 33  SHARES %fq0@[ 0..63],
    %fd2  [64] -> 34  SHARES %fq2@[64..127],
    %fd3  [64] -> 35  SHARES %fq2@[ 0..63],
    %fd4  [64] -> 36  SHARES %fq4@[64..127],
    %fd5  [64] -> 37  SHARES %fq4@[ 0..63],
    %fd6  [64] -> 38  SHARES %fq6@[64..127],
    %fd7  [64] -> 39  SHARES %fq6@[ 0..63],
    %fd8  [64] -> 40  SHARES %fq8@[64..127],
    %fd9  [64] -> 41  SHARES %fq8@[ 0..63],
    %fd10 [64] -> 42  SHARES %fq10@[64..127],
    %fd11 [64] -> 43  SHARES %fq10@[ 0..63],
    %fd12 [64] -> 44  SHARES %fq12@[64..127],
    %fd13 [64] -> 45  SHARES %fq12@[ 0..63],
    %fd14 [64] -> 46  SHARES %fq14@[64..127],
    %fd15 [64] -> 47  SHARES %fq14@[ 0..63],
    %fd16 [64] -> 48  SHARES %fq16@[64..127],
    %fd17 [64] -> 49  SHARES %fq16@[ 0..63],
    %fd18 [64] -> 50  SHARES %fq18@[64..127],
    %fd19 [64] -> 51  SHARES %fq18@[ 0..63],
    %fd20 [64] -> 52  SHARES %fq20@[64..127],
    %fd21 [64] -> 53  SHARES %fq20@[ 0..63],
    %fd22 [64] -> 54  SHARES %fq22@[64..127],
    %fd23 [64] -> 55  SHARES %fq22@[ 0..63],
    %fd24 [64] -> 56  SHARES %fq24@[64..127],
    %fd25 [64] -> 57  SHARES %fq24@[ 0..63],
    %fd26 [64] -> 58  SHARES %fq26@[64..127],
    %fd27 [64] -> 59  SHARES %fq26@[ 0..63],
    %fd28 [64] -> 60  SHARES %fq28@[64..127],
    %fd29 [64] -> 61  SHARES %fq28@[ 0..63],
    %fd30 [64] -> 62  SHARES %fq30@[64..127],
    %fd31 [64] -> 63  SHARES %fq30@[ 0..63],
#
    %fr0  [32] -> 64  SHARES %fd0@[32..63],
    %fr0R [32] -> 96  SHARES %fd0@[ 0..31],
    %fr1  [32] -> 65  SHARES %fd1@[32..63],
    %fr1R [32] -> 97  SHARES %fd1@[ 0..31],
    %fr2  [32] -> 66  SHARES %fd2@[32..63],
    %fr2R [32] -> 98  SHARES %fd2@[ 0..31],
    %fr3  [32] -> 67  SHARES %fd3@[32..63],
    %fr3R [32] -> 99  SHARES %fd3@[ 0..31],
    %fr4  [32] -> 68  SHARES %fd4@[32..63],
    %fr4R [32] -> 100 SHARES %fd4@[ 0..31],
    %fr5  [32] -> 69  SHARES %fd5@[32..63],
    %fr5R [32] -> 101 SHARES %fd5@[ 0..31],
    %fr6  [32] -> 70  SHARES %fd6@[32..63],
    %fr6R [32] -> 102 SHARES %fd6@[ 0..31],
    %fr7  [32] -> 71  SHARES %fd7@[32..63],
    %fr7R [32] -> 103 SHARES %fd7@[ 0..31],
    %fr8  [32] -> 72  SHARES %fd8@[32..63],
    %fr8R [32] -> 104 SHARES %fd8@[ 0..31],
    %fr9  [32] -> 73  SHARES %fd9@[32..63],
    %fr9R [32] -> 105 SHARES %fd9@[ 0..31],
    %fr10 [32] -> 74  SHARES %fd10@[32..63],
    %fr10R[32] -> 106 SHARES %fd10@[ 0..31],
    %fr11 [32] -> 75  SHARES %fd11@[32..63],
    %fr11R[32] -> 107 SHARES %fd11@[ 0..31],
    %fr12 [32] -> 76  SHARES %fd12@[32..63],
    %fr12R[32] -> 108 SHARES %fd12@[ 0..31],
    %fr13 [32] -> 77  SHARES %fd13@[32..63],
    %fr13R[32] -> 109 SHARES %fd13@[ 0..31],
    %fr14 [32] -> 78  SHARES %fd14@[32..63],
    %fr14R[32] -> 110 SHARES %fd14@[ 0..31],
    %fr15 [32] -> 79  SHARES %fd15@[32..63],
    %fr15R[32] -> 111 SHARES %fd15@[ 0..31],
    %fr16 [32] -> 80  SHARES %fd16@[32..63],
    %fr16R[32] -> 112 SHARES %fd16@[ 0..31],
    %fr17 [32] -> 81  SHARES %fd17@[32..63],
    %fr17R[32] -> 113 SHARES %fd17@[ 0..31],
    %fr18 [32] -> 82  SHARES %fd18@[32..63],
    %fr18R[32] -> 114 SHARES %fd18@[ 0..31],
    %fr19 [32] -> 83  SHARES %fd19@[32..63],
    %fr19R[32] -> 115 SHARES %fd19@[ 0..31],
    %fr20 [32] -> 84  SHARES %fd20@[32..63],
    %fr20R[32] -> 116 SHARES %fd20@[ 0..31],
    %fr21 [32] -> 85  SHARES %fd21@[32..63],
    %fr21R[32] -> 117 SHARES %fd21@[ 0..31],
    %fr22 [32] -> 86  SHARES %fd22@[32..63],
    %fr22R[32] -> 118 SHARES %fd22@[ 0..31],
    %fr23 [32] -> 87  SHARES %fd23@[32..63],
    %fr23R[32] -> 119 SHARES %fd23@[ 0..31],
    %fr24 [32] -> 88  SHARES %fd24@[32..63],
    %fr24R[32] -> 120 SHARES %fd24@[ 0..31],
    %fr25 [32] -> 89  SHARES %fd25@[32..63],
    %fr25R[32] -> 121 SHARES %fd25@[ 0..31],
    %fr26 [32] -> 90  SHARES %fd26@[32..63],
    %fr26R[32] -> 122 SHARES %fd26@[ 0..31],
    %fr27 [32] -> 91  SHARES %fd27@[32..63],
    %fr27R[32] -> 123 SHARES %fd27@[ 0..31],
    %fr28 [32] -> 92  SHARES %fd28@[32..63],
    %fr28R[32] -> 124 SHARES %fd28@[ 0..31],
    %fr29 [32] -> 93  SHARES %fd29@[32..63],
    %fr29R[32] -> 125 SHARES %fd29@[ 0..31],
    %fr30 [32] -> 94  SHARES %fd30@[32..63],
    %fr30R[32] -> 126 SHARES %fd30@[ 0..31],
    %fr31 [32] -> 95  SHARES %fd31@[32..63],
    %fr31R[32] -> 127 SHARES %fd31@[ 0..31];

CARRY_BORROWS(one, two, sa, three) {
    _
};

CARRY_SLA_BORROWS(one, two, three) {
    _
};


OPERAND
    c_c := {    c_c_no,
                c_c_eq,
                c_c_l,
                c_c_le,
                c_c_ul,
                c_c_ule,
                c_c_sv,
                c_c_od,

                c_c_yes,
                c_c_ne,
                c_c_ge,
                c_c_g,
                c_c_uge,
                c_c_ug,
                c_c_nsv,
                c_c_ev
        },
    
    c_c_no  [ r1, r2, t ] *1* 0,
    c_c_yes [ r1, r2, t ] *1* 1,
# "Result based"
    c_c_eq  [ r1, r2, t ] *1* t = 0,
    c_c_ne  [ r1, r2, t ] *1* t ~= 0,
    c_c_l   [ r1, r2, t ] *1* t < 0,
    c_c_ge  [ r1, r2, t ] *1* t >= 0,
    c_c_le  [ r1, r2, t ] *1* t <= 0,
    c_c_g   [ r1, r2, t ] *1* t > 0,
# "Operand based"
#    c_c_eq  [ r1, r2, t ] *1* r1 = r2,
#    c_c_ne  [ r1, r2, t ] *1* r1 ~= r2,
#    c_c_l   [ r1, r2, t ] *1* r1 < r2,
#    c_c_ge  [ r1, r2, t ] *1* t >= 0,
#    c_c_le  [ r1, r2, t ] *1* t <= 0,
#    c_c_g   [ r1, r2, t ] *1* t > 0,
# Unsigneds pretty much have to be "operand based", since you can't unsigned
# compare with zero
    c_c_ul  [ r1, r2, t ] *1* r1 <u r2,
    c_c_uge [ r1, r2, t ] *1* r1 >=u r2,
    c_c_ule [ r1, r2, t ] *1* r1 <=u r2,
    c_c_ug  [ r1, r2, t ] *1* r1 >u r2,
    c_c_sv  [ r1, r2, t ] *1* 0,
    c_c_nsv [ r1, r2, t ] *1* 1,
    c_c_od  [ r1, r2, t ] *1* (t & 1),
    c_c_ev  [ r1, r2, t ] *1* ~(t & 1);

#COND_ARITH  := { "0", "1", "%ZF", "~%ZF",
#                 "%NF ^ %OF", "~(%NF ^ %OF)", "%ZF | (%NF ^ %OF)", "~(%ZF & (%NF ^ %OF))",
#                 "~%CF", "%CF", "%ZF | ~%CF", "~%ZF & %CF",
#                 "%OF", "~%OF", "%NF", "~%NF" };
#CONDC_ARITH := { "%ZF", "~%ZF",
#                 "%NF ^ %OF", "~(%NF ^ %OF)", "%ZF | (%NF ^ %OF)", "~(%ZF & (%NF ^ %OF))",
#                 "~%CF", "%CF", "%ZF | ~%CF", "~%ZF & %CF",
#                 "%OF", "~%OF", "%NF", "~%NF" };

CARRY_VAL  := { "%CF", "0" };
BORR_VAL   := { "%CF", "1" };

sub_b := { "SUB_b", "SUB_b_v" };
subs := { "SUB", sub_b };

add_c := { "ADD_c", "ADD_c_v" };
adds := { "ADD", add_c };


SUB             r1, r2, t, c_c
                *32* r[tmp1] := r[r1] - r[r2];
sub_b[x]        r1, r2, t, c_c
                *32* r[tmp1] := r[r1] - r[r2] + (1 - %CF);
subs[x]         r1, r2, t, c_c
                CARRY_BORROWS(r[tmp1], r[r1], r[r2]);

ADD             r1, r2, t, c_c
                *32* r[tmp1] := r[r1] + r[r2];
add_c[x]        r1, r2, t, c_c
                *32* r[tmp1] := r[r1] + r[r2] + %CF;
adds[x]         r1, r2, t, c_c
                CARRY_BORROWS(r[tmp1], r[r1], r[r2]);

ADDL            r1, r2, t, c_c
                *32* r[tmp1] := r[r1] + r[r2];

OR              r1, r2, t, c_c
                *32* r[tmp1] := r[r1] | r[r2];

XOR             r1, r2, t, c_c
                *32* r[tmp1] := r[r1] ^ r[r2];
                

AND             r1, r2, t, c_c
                *32* r[tmp1] := r[r1] & r[r2];

                
ANDCM           r1, r2, t, c_c
                *32* r[t] := r[r1] & ~r[r2];

add_conds := { $adds, "ADDL", "OR", "XOR", "AND", "ANDCM" };
sub_conds := { $subs };

add_conds[x]    r1, r2, t, c_c
                *32* r[tmpNul] := c_c(r[r1], 0-r[r2], r[tmp1])
                *32* r[t] := r[tmp1];
                
sub_conds[x]    r1, r2, t, c_c
                *32* r[tmpNul] := c_c(r[r1], r[r2], r[tmp1])
                *32* r[t] := r[tmp1];





ADDIL           imm21, r1
                *32* r[1] := r[r1] + imm21;

SHIFT_VAL   := { "1", "2", "3" };

shladds := { "SHL1ADD", "SHL2ADD", "SHL3ADD" };
l_ := { "L", "" };
shladds[a]$l_[x]    r1, r2, t, c_c
                    *32* r[tmp2] := r[r1] << SHIFT_VAL[a]
                    *32* r[tmp1] := r[tmp2] + r[r2];
shladds[a]          r1, r2, t, c_c
                    CARRY_BORROWS(r[tmp1], r[tmp2], r[r2]);
shladds[a]$l_[x]    r1, r2, t, c_c
                    *32* r[tmpNul] := c_c(r[tmp2], 0-r[r2], r[tmp1])
                    *32* r[t] := r[tmp1];

VSHD            r1, r2, t, c_c
                *32* r[tmp1] := fsize(64, 32, ((fsize(32, 64, r[r1]) << 32) |
                                               (fsize(32, 64, r[r2]))) >> %sar)
                *32* r[tmpNul] := c_c(r[r1], r[r2], r[tmp1])
                *32* r[t] := r[tmp1];

SHD             r1, r2, sa, t, c_c
                *32* r[tmp1] := fsize(64, 32, ((fsize(32, 64, r[r1]) << 32) |
                                               (fsize(32, 64, r[r2]))) >> sa)
                *32* r[tmpNul] := c_c(r[r1], r[r2], r[tmp1])
                *32* r[t] := r[tmp1];

EXTRS           r, p, len, t, c_c
                *32* r[tmp1] := (r[r] << (p + 1 - len)) >>A (31 - len + 1)
                *32* r[tmpNul] := c_c(r[r], r[r], r[tmp1])
                *32* r[t] := r[tmp1];

EXTRU           r, p, len, t, c_c
                *32* r[tmp1] := (r[r] << (p + 1 - len)) >> (31 - len + 1)
                *32* r[tmpNul] := c_c(r[r], r[r], r[tmp1])
                *32* r[t] := r[tmp1];

DEP             r, p, len, t, c_c
                *32* (len > p+1) =>
                    r[tmp1] := ((r[r] << (32 - len)) << (len - 1 - p))
                        | (r[t] & ~(( -1  << (32 - len)) >> (len - 1 - p)))
                *32* (len <= p+1) =>
                    r[tmp1] := ((r[r] << (32 - len)) >> (p - len + 1))
                        | (r[t] & ~(( -1  << (32 - len)) >> (p - len + 1)))
                *32* r[tmpNul] := c_c(r[r], r[r], r[tmp1])
                *32* r[t] := r[tmp1];

DEPI            i, p, len, t, c_c
                *32* (len > p+1) =>
                    r[tmp1] := ((i << (32 - len)) << (len - 1 - p))
                        | (r[t] & ~(( -1  << (32 - len)) >> (len - 1 - p)))
                *32* (len <= p+1) =>
                    r[tmp1] := ((i << (32 - len)) >> (p - len + 1))
                        | (r[t] & ~(( -1  << (32 - len)) >> (p - len + 1)))
                *32* r[tmpNul] := c_c(i, i, r[tmp1])
                *32* r[t] := r[tmp1];

VDEP            r, len, t, c_c
                *32* (len > %sar+1) =>
                    r[tmp1] := ((r[r] << (32 - len)) << (len - 1 - %sar))
                        | (r[t] & ~(( -1  << (32 - len)) >> (len - 1 - %sar)))
                *32* (len <= %sar+1) =>
                    r[tmp1] := ((r[r] << (32 - len)) >> (%sar - len + 1))
                        | (r[t] & ~(( -1  << (32 - len)) >> (%sar - len + 1)))
                *32* r[tmpNul] := c_c(r[r], r[r], r[tmp1])
                *32* r[t] := r[tmp1];

VDEPI           i, len, t, c_c
                *32* (len > %sar+1) =>
                    r[tmp1] := ((i << (32 - len)) << (len - 1 - %sar))
                        | (r[t] & ~(( -1  << (32 - len)) >> (len - 1 - %sar)))
                *32* (len <= %sar+1) =>
                    r[tmp1] := ((i << (32 - len)) >> (%sar - len + 1))
                        | (r[t] & ~(( -1  << (32 - len)) >> (%sar - len + 1)))
                *32* r[tmpNul] := c_c(i, i, r[tmp1])
                *32* r[t] := r[tmp1];

ZDEP            r, p, len, t, c_c
                *32* (len > p+1) =>
                    r[tmp1] := (r[r] << (32 - len)) << (len - 1 - p)
                *32* (len <= p+1) =>
                    r[tmp1] := (r[r] << (32 - len)) >> (p - len + 1)
                *32* r[tmpNul] := c_c(r[r], r[r], r[tmp1])
                *32* r[t] := r[tmp1];

ZDEPI           i, p, len, t, c_c
                *32* (len > p+1) =>
                    r[tmp1] := (i << (32 - len)) << (len - 1 - p)
                *32* (len <= p+1) =>
                    r[tmp1] := (i << (32 - len)) >> (p - len + 1)
                *32* r[tmpNul] := c_c(i, i, r[tmp1])
                *32* r[t] := r[tmp1];

ZVDEP           r, len, t, c_c
                *32* (len > %sar+1) =>
                    r[tmp1] := (r[r] << (32 - len)) << (len - 1 - %sar)
                *32* (len <= %sar+1) =>
                    r[tmp1] := (r[r] << (32 - len)) >> (%sar - len + 1)
                *32* r[tmpNul] := c_c(r[r], r[r], r[tmp1])
                *32* r[t] := r[tmp1];

ZVDEPI          i, len, t, c_c
                *32* (len > %sar+1) =>
                    r[tmp1] := (i << (32 - len)) << (len - 1 - %sar)
                *32* (len <= %sar+1) =>
                    r[tmp1] := (i << (32 - len)) >> (%sar - len + 1)
                *32* r[tmpNul] := c_c(i, i, r[tmp1])
                *32* r[t] := r[tmp1];

CMPCLR          r1, r2, t, c_c
                *32* r[tmp1] := r[r1] - r[r2]
                *32* r[tmpNul] := c_c(r[r1], r[r2], r[tmp1])
                *32* r[t] := 0;

CMPICLR         i, r, t, c_c
                *32* r[tmp1] := i - r[r]
                *32* r[tmpNul] := c_c(i, r[r], r[tmp1])
                *32* r[t] := 0;

addis := { "ADDI", "ADDIt", "ADDItv", "ADDIv" };
addis[x]        i, r, t, c_c
                *32* r[tmp1] := i + r[r]
                *32* r[tmpNul] := c_c(i, 0-r[r], r[tmp1])
                *32* r[t] := r[tmp1];

subis := { "SUBI", "SUBIv" };
subis[x]        i, r, t, c_c
                *32* r[tmp1] := i - r[r]
                *32* r[tmpNul] := c_c(i, r[r], r[tmp1])
                *32* r[t] := r[tmp1];


MOVB            r1, r2
                *32* r[r2] := r[r1];

MOVIB           i, r
                *32* r[r] := i;

# The following is the add part (only) of add immediate and branch
addibs := {"ADDIBt", "ADDIBf"};
addibs[x]       i, r
                *32* r[r] := i + r[r];

# The following is the add part (only) of add and branch
addbs := {"ADDBt", "ADDBf"};
addbs[x]        r1, r2
                *32* r[r2] := r[r1] + r[r2];


MTCTL           r, t
                # t must be 11 for this to be a valid user level instruction
                *32* %sar := r[r] & 0x1F;

NOP
                _ ;


OPERAND
      c_xd := { x_addr_nots, x_addr_s_byte, x_addr_s_hwrd, x_addr_s_word,
         x_addr_s_dwrd, s_addr_im_r, s_addr_r_im, l_addr_16_old,
         l_addr_17_old },
      x_addr_nots   xd [a] *32* r[xd],
      x_addr_s_byte xd [a] *32* r[xd],
      x_addr_s_hwrd xd [a] *32* r[xd] << 1,
      x_addr_s_word xd [a] *32* r[xd] << 2,
      x_addr_s_dwrd xd [a] *32* r[xd] << 3,
      s_addr_im_r   xd [a] *32* xd,
      s_addr_r_im   xd [a] *32* xd,
      l_addr_16_old xd [a] *32* xd,
      l_addr_17_old xd [a] *32* xd;



OPERAND
        c_addr := { c_s_addr_mb, c_s_addr_ma, c_s_addr_notm,
            c_x_addr_m, c_x_addr_notm,
            c_y_addr_e, c_y_addr_m, c_y_addr_me, c_y_addr_none,
            c_l_addr_none },

        c_s_addr_mb     [ a ] *32* -1,
        c_s_addr_ma     [ a ] *32* 1,
        c_s_addr_notm   [ a ] *32* 0,

        c_x_addr_m      [ a ] *32* 1,
        c_x_addr_notm   [ a ] *32* 0,

		c_y_addr_none   [ a ] *32* 0,
        c_y_addr_e      [ a ] *32* 0,
        c_y_addr_m      [ a ] *32* 0,
        c_y_addr_me     [ a ] *32* 0,

        c_l_addr_none   [ a ] *32* 0;

#
# Loads and Stores
#
LDIL            i, t
                *32* r[t] := i;

LDO             d, b, t
                *32* r[t] := addr( m[ d + r[b]]);


LDW_ := LDW{ "X", "S", "M", "AX", "AS", "" };
LDW_[x]         c_addr, c_xd, s, b, t
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0)
                *32* r[t] := m[r[tmp1]]{32};

LDB_ := LDB{"X", "S", ""};
LDB_[x]         c_addr, c_xd, s, b, t
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0)
                *8*  r[t] := zfill(8,  32, m[r[tmp1]]);

LDH_ := LDH{"X", "S", ""};
LDH_[x]         c_addr, c_xd, s, b, t
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0)
                *16* r[t] := zfill(16, 32, m[r[tmp1]]);

STW_ := STW{"AS", "M", "S", ""};
STW_[x]         c_addr, r1, c_xd, s, b
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
                *32* m[r[tmp1]] := r[r1]
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0);

STB_ := STB{"S", ""};
STB_[x]         c_addr, r1, c_xd, s, b
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
                *8*  m[r[tmp1]] := truncs(32, 8, r[r1])
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0);

STH_ := STH{"S", ""};
STH_[x]         c_addr, r1, c_xd, s, b
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
                *16* m[r[tmp1]] := truncs(32, 16, r[r1])
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0);

# Floating point loads and stores
FLDW_ := FLDW{"X", "S"};
FLDW_[x]        c_addr, c_xd, s, b, ft
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0)
                *32* r[ft] := m[r[tmp1]]{32};

FLDD_ := FLDD{"X", "S"};
FLDD_[x]        c_addr, c_xd, s, b, fdt
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0)
                *64* r[fdt] := m[r[tmp1]]{64};

FSTW_ := FSTW{"X", "S"};
FSTW_[x]        c_addr, fr1, c_xd, s, b
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
                *32* m[r[tmp1]] := r[fr1]
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0);

FSTD_ := FSTD{"X", "S"};
FSTD_[x]        c_addr, fr1, c_xd, s, b
				*32* r[tmp1] := r[b]
				*32* (c_addr(0) < 1) => r[tmp1] := r[tmp1] + c_xd(0)
                *64* m[r[tmp1]] := r[fr1]
				*32* (c_addr(0) ~= 0) => r[b] := r[b] + c_xd(0);


OPERAND
    c_bit := { bitpos_fix, bitpos_sar },
    bitpos_fix s [ a ] *32* 1 << (31 - s),
    bitpos_sar s [ a ] *32* 1 << (31 - %sar);

#
# Branches
#
# BL: branch and link

BL              ubr_target, t_06
                *32* r[tmp1] := %pc  
                *32* %pc := %npc
                *32* %npc := r[tmp1] + ubr_target
                *32* r[t_06] := %npc + 4; 

#B.l c_null, ubr_target!, t_06     *32* r[tmp] := %pc 
#                                    *32* %pc := %npc
#                                    *32* %npc := r[tmp] + ubr_target! 
#                                    *32* r[t_06] := %npc + 8

BV              x_reg, base_reg 
                *32* %pc := %npc 
                *32* %npc := r[base_reg] + (r[x_reg] << 3); 

#BV.n            x_reg, base_reg
#                *32* %pc := r[base_reg] + (r[x_reg] << 3) 
#                *32* %npc := %pc + 4; 

BREAK           im5, im13
                _ ;

#
# Floating point class 0
#

FCPY            fmt, rf, tf
                *32* (fmt = 0) => r[tf] := r[rf]
                *64* (fmt = 1) => r[tf] := r[rf]
                *128*(fmt = 3) => r[tf] := r[rf];

FABS            fmt, rf, tf
                *32* (fmt = 0) => r[tf] := [ r[rf] < 0.0 ? 0.0 -f r[rf]
                    : r[rf] ]
                *64* (fmt = 1) => r[tf] := [ r[rf] < 0.0 ? 0.0 -f r[rf]
                    : r[rf] ]
                *128*(fmt = 3) => r[tf] := [ r[rf] < 0.0 ? 0.0 -f r[rf]
                    : r[rf] ];

FSQRT           fmt, rf, tf
                *32* (fmt = 0) => r[tf] := sqrt(r[rf])
                *64* (fmt = 1) => r[tf] := sqrt(r[rf])
                *128*(fmt = 3) => r[tf] := sqrt(r[rf]);

#FRND            fmt, rf, tf
#                *32* 

#
# Floating point class 1
#

fcnvff_ := FCNVFF{ "E", ""};
fcnvff_[x]       fs, df, rf, tf
# Single to double
                *64* ((fs = 0) & (df = 1)) => r[tf] := fsize(32, 64, r[rf])
# Double to single
                *32* ((fs = 1) & (df = 0)) => r[tf] := fsize(64, 32, r[rf])
# Single to quad
                *128*((fs = 0) & (df = 3)) => r[tf] := fsize(32, 128,r[rf])
# Quad to single
                *32* ((fs = 3) & (df = 0)) => r[tf] := fsize(128,32, r[rf])
# Double to quad
                *128*((fs = 1) & (df = 3)) => r[tf] := fsize(64, 128,r[rf])
# Quad to double
                *64* ((fs = 3) & (df = 1)) => r[tf] := fsize(128,64, r[rf]);

FCNVXF          sf, df, rf, tf
# Convert from fixed point (integer) to float. Not sure what sf is for
                *32* (df = 0) => r[tf] := itof(32, 32, r[rf])
                *64* (df = 1) => r[tf] := itof(32, 64, r[rf])
                *128*(df = 3) => r[tf] := itof(32, 128,r[rf]);

#
# Floating point class 3
#

fadd_ := FADD{ "E", "" };
fadd_[x]        fmt, fr1, fr2, frt
                *32* (fmt = 0) => r[frt] := r[fr1] +f r[fr2]
                *64* (fmt = 1) => r[frt] := r[fr1] +f r[fr2]
                *128*(fmt = 3) => r[frt] := r[fr1] +f r[fr2];

fsub_ := FSUB{ "E", "" };
fsub_[x]        fmt, fr1, fr2, frt
                *32* (fmt = 0) => r[frt] := r[fr1] -f r[fr2]
                *64* (fmt = 1) => r[frt] := r[fr1] -f r[fr2]
                *128*(fmt = 3) => r[frt] := r[fr1] -f r[fr2];

fmpy_ := FMPY{ "E", "" };
fmpy_[x]        fmt, fr1, fr2, frt
                *32* (fmt = 0) => r[frt] := r[fr1] *f r[fr2]
                *64* (fmt = 1) => r[frt] := r[fr1] *f r[fr2]
                *128*(fmt = 3) => r[frt] := r[fr1] *f r[fr2];

fdiv_ := FDIV{ "E", "" };
fdiv_[x]        fmt, fr1, fr2, frt
                *32* (fmt = 0) => r[frt] := r[fr1] /f r[fr2]
                *64* (fmt = 1) => r[frt] := r[fr1] /f r[fr2]
                *128*(fmt = 3) => r[frt] := r[fr1] /f r[fr2];

# Note: This instruction performs unsigned multiplication in floating point
# registers! (It's also 32 * 32 -> 64 bit)
XMPYU           fr1, fr2, frt
                *64* r[frt] := zfill(32, 64, r[fr1]) * zfill(32, 64, r[fr2]);
                

